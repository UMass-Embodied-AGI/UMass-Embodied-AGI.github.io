
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script src="bootstrap.js"></script>
<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script> 
<!---
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
--->
<script src="load-mathjax.js" async></script>
<script>
    function setImageGLIDE(select){
       var image = document.getElementsByName("image-swap-1")[0];
       image.src = select.options[select.selectedIndex].value;
    }
    function setImageStable(select){
       var image = document.getElementsByName("image-swap-2")[0];
       image.src = select.options[select.selectedIndex].value;
    }
</script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}


h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #5364cc;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}

.move-down {
    margin-top:1.2cm;
}

.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new { 
    text-align: center; 
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0; 
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
	text-align: left;
}


video {
    display: block;
    margin: auto;
}


figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #2c82c9;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative; 
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.center {
  margin-left: 10.0%;
  margin-right: 10.0%;
}

.paper-btn {
  position: relative;
  text-align: center;

  display: inline-block;
  margin: 8px;
  padding: 8px 8px;

  border-width: 0;
  outline: none;
  border-radius: 2px;
  
  background-color: #5364cc;
  color: white !important;
  font-size: 20px;
  width: 100px;
  font-weight: 600;
}
.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.paper-btn:hover {
    opacity: 0.85;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.column4 {
  text-align: center;
  float: left;
  width: 50%;
  padding: 5px;
}
.column5 {
  text-align: center;
  float: left;
  width: 20%;
  padding: 5px;
}
.column10 {
  text-align: center;
  float: left;
  width: 10%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}


.row-center {
    margin: 16px 0px 16px 0px;
    text-align: center;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
.img-fluid {
  max-width: 100%;
  height: auto;
}
.figure-img {
  margin-bottom: 0.5rem;
  line-height: 1;
}








.rounded-circle {
  border-radius: 50% !important;
}






/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>
<link rel="stylesheet" href="bootstrap-grid.css">

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title> Mod-Squad: Designing Mixtures of Experts As Modular Multi-Task Learners</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners"/>
        <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="@yining_hong">
        <meta name="twitter:title" content="Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners">
        <meta name="twitter:description" content="">
        <meta name="twitter:image" content="">
    </head>

 <body>


<div class="container">
    <div class="paper-title">
    <h1> 
        Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="http://chenzt.net/"> Zitian Chen<sup>1</sup></a>,
                <a href=""> Yikang Shen<sup>2</sup></a>,
                <a href=""> Mingyu Ding<sup>3</sup></a>,
                <br>
                <a href="https://zfchenunique.github.io/"> Zhenfang Chen<sup>2</sup></a>,
                <a href=""> Hengshuang Zhao<sup>3</sup></a>,
                <a href="https://people.cs.umass.edu/~elm/"> Erik Learned-Miller<sup>1,2</sup></a>,
                <a href="https://people.csail.mit.edu/ganchuang/"> Chuang Gan<sup>1,2</sup></a>,
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup> University of Massachusetts Amherst</span>
            <span><sup>2</sup> MIT-IBM Watson AI Lab</span>
            <span><sup>3</sup> The University of Hong Kong</span>
        </div>

        <div class="affil-row">
            <div class="venue text-center"><b>CVPR 2023 </b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
            <a class="paper-btn" href="https://arxiv.org/abs/2212.08066">
                <span class="material-icons"> description </span> 
                 Paper
            </a>
            <a class="paper-btn" href="https://github.com/tankche1/Mod-squad">
                <span class="material-icons"> code </span>
                Code
            </a>
            </div>
        </div>
    </div>


    <section id="teaser-image">
        <!-- <div style="display: flex;">
                <video src="materials/annimation.mp4" class="centered" width="70%" autoplay loop muted playsinline class="video-background" name="image-swap-2" >
                <img width="20%" src="materials/motivation.png"> 
        </div> -->
        <div style="display: flex; align-items: center;">
          <!-- Insert the video element -->
          <video src="materials/annimation.mp4" autoplay loop muted playsinline width="85%"></video>
          <!-- Insert the image element -->
          <!-- <img width="50%" src="materials/motivation.png" alt="Description of the image"> -->
        </div>
    </section>

    
    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
                Optimization in multi-task learning (MTL) is more challenging than single-task learning (STL), as the gradient from different tasks can be contradictory. When tasks are related, it can be beneficial to share some parameters among them (cooperation). However, some tasks require additional parameters with expertise in a specific type of data or discrimination (specialization). 
                To address the MTL challenge, we propose <strong><em>model</em></strong>, a new model that is <strong>mod</strong>ularized into groups of experts (a '<strong>squad</strong>'). This structure allows us to formalize cooperation and specialization as the process of matching experts and tasks. We optimize this matching process during the training of a single model. Specifically, we incorporate mixture of experts (MoE) layers into a transformer model, with a new loss that incorporates the mutual dependence between tasks and experts. As a result, only a small set of experts are activated for each task. This prevents the sharing of the entire backbone model between all tasks, which strengthens the model, especially when the training set size and the number of tasks scale up.
                More interestingly, for each task, we can extract the small set of experts as a standalone model that maintains the same performance as the large model.
                Extensive experiments on the Taskonomy dataset with 13 vision tasks and the PASCAL-Context dataset with 5 vision tasks show the superiority of our approach.
            </p>
        </div>
    </section>
    <section id="dataset"/>
        <hr>
        <h2>Key motivation: a sparse and strong dependence between experts and tasks</h2>
        <div class="flex-row">
                <p>
                    Our key motivation is that experts should leverage commonalities
                    in some tasks (cooperation) but focus on a subset of tasks that
                    require specific features and do not interfere with each other (specialization).
                </p>
            
        </div>
        <figure>
            <center>
                <a>
                    <img width="60%" src="materials/motivation.png"> 
                </a>
               
                <!-- <a>
                    <img width="55%" src="materials/compare_expert_task.png"> 
                </a> -->    
                <div style="display: flex; justify-content: center;">
                    <p class="caption">
                        A comparison between Mod-Squad and MoE ViT.
                    </p>
                </div>
            </center>
        </figure>

        <div class="flex-row">
                <p>
                    A real visualization of the relation between task and experts:
                </p>
            
        </div>

        <figure>
            <center>
                <a>
                    <img width="60%" src="materials/compare_expert_task.png"> 
                </a>   
                <div style="display: flex; justify-content: center;">
                    <p class="caption">
                        A comparison between Mod-Squad and other MoE. The y-axis represents the tasks and the x-axis represents the 15 experts. Our frequency map is much sharp and sparse than other methods.
                    </p>
                </div>
            </center>
        </figure>

    </section>
    <section id="method"/>
        <hr>
        <h2>Mod-Squad Framework</h2>
        

        <div class="flex-row">
            <p> 
                A key design in our model is customizing MoE into the vision transformer so that each expert can construct a minimum part of the model that can be either shared between tasks or specialized for tasks.
            </p>
        </div>

        <figure>
            <a>
                <img width="100%" src="materials/pipeline.png"> 
            </a>
            <div style="display: flex; justify-content: center;">
                <p class="caption">
                    The pipeline of our multi-task foundation model. Each transformer block in Mod-Squad consists a MoE attention network
                    (MoE attn.) and a MoE MLP neswork. The multi-task model Mod-Squad is trained with our proposed mutual information loss.
            </div>
        </figure>

        <h2>Mutual Information between Experts and Tasks</h2>

        <figure>
            <a>
                <img width="100%" src="materials/MI_gain_screenshot.png"> 
            </a>
            <div style="display: flex; justify-content: center;">
                <p class="caption">
                    Maximize mutual information develop a sharp and sparse relation between experts and tasks.
            </div>
        </figure>

    </section>
        

    <section id="results">
        <hr>
        <h2>Extracting Sub-Network for an Individual Task</h2>  

        <figure>
            <a>
                <img width="100%" src="materials/pruning.png"> 
            </a>
            <div style="display: flex; justify-content: center;">
                <p class="caption">
                    Mod-squad can be pruned without addition training and performance drop.
            </div>
        </figure>

        <!-- <hr> -->


        <h2>Strong Multi-task Foundation Model</h2>  

        <figure>
            <a>
                <img width="48%" src="materials/result.png"> 
            </a>
            <a>
                <img width="48%" src="materials/tasks.png"> 
            </a>
            <div style="display: flex; justify-content: center;">
                <p class="caption">
                    Mod-squad can learn the relation between tasks and be a strong MTL learner.
            </div>
        </figure>

    </section> 

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre><code>@article{chen2022modsquad,
            title={Mod-Squad: Designing Mixtures of Experts As Modular Multi-Task Learners},
            author={Zitian Chen and Yikang Shen and Mingyu Ding and Zhenfang Chen and Hengshuang Zhao and Erik Learned-Miller and Chuang Gan},
            journal={CVPR},
            year={2023}
}</code></pre>
</section>




    

</div>
</body>
</html>
