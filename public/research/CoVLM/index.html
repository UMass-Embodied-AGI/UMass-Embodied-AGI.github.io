<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Compose visual entities and relationships in LLMs via communicative decoding.">
  <meta name="keywords" content="Vision-language Models, Compositionality">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CoVLM</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<style>
  .rainbow-text {
    font-family: Arial;
    font-weight: bold;
    font-size: 50px;
    text-shadow: #A3A3A3 1px 1px 1px;
  }
  .rainbow-text .block-line > span {
    display: inline-block;
  }
  .subheader {
    margin-top: 0;
    margin-bottom: 10px;
    font-family: 'Open Sans', sans-serif;
    color: #333;
    font-size: 25px;
    line-height: 44px;
    font-weight: 500;
    letter-spacing: 0;
  }
</style>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="subheader"><span class="rainbow-text"><span style="color:#80ed12;">C</span><span style="color:#A5D604;">o</span><span style="color:#C7B601;">V</span><span style="color:#E39209;">L</span><span style="color:#F66C1C;">M</span></span>
            <br>Composing Visual Entities and Relationships in <br>Large Language Models Via Communicative Decoding</h1>
          <!-- <h3 class="title is-5 conference-authors">ICLR 2024 Submission</h3> -->
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div style="font-size: 18px;"><a href="https://senfu.github.io" style="color: black;">Junyan Li</a><sup>1</sup>, <a href="https://chendl02.github.io" style="color: black;">Delin Chen</a><sup>2</sup>, <a href="https://evelinehong.github.io" style="color: black;">Yining Hong</a><sup>3</sup>, <a href="https://zfchenunique.github.io" style="color: black;">Zhenfang Chen</a><sup>4</sup>,</div>
          <div style="font-size: 18px;"><a href="https://peihaochen.github.io" style="color: black;">Peihao Chen</a><sup>5</sup>, <a href="https://scholar.google.com.hk/citations?user=qff5rRYAAAAJ" style="color: black;">Yikang Shen</a><sup>4</sup>, <a href="https://people.csail.mit.edu/ganchuang" style="color: black;">Chuang Gan</a><sup>1,4</sup></div>
        </div>
      </div>
      <div class="columns is-centered">
        <div class="column has-text-centered" style="font-size: 14px;">
          <sup>1</sup>UMass Amherst&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup>Wuhan University&nbsp;&nbsp;&nbsp;&nbsp;<sup>3</sup>University of California, Los Angeles
          <br>
          <sup>4</sup>MIT-IBM Watson AI Lab&nbsp;&nbsp;&nbsp;&nbsp;<sup>5</sup>South China University of Technology
        </div>
      </div>
      <div class="columns is-centered">
        <a href="https://arxiv.org/abs/2311.03354" target="_blank" class="external-link button is-normal is-rounded is-dark" style="margin: 10px;">
          <span class="icon">
              <i class="ai ai-arxiv"></i>
          </span>
          <span>Paper</span>
        </a>
        <a href="https://github.com/UMass-Foundation-Model/CoVLM" target="_blank" class="external-link button is-normal is-rounded is-dark" style="margin: 10px;">
          <span class="icon">
              <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
          </span>
          <span>Code</span>
        </a>
        <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark" style="margin: 10px;">
          <span class="icon">
            ðŸ¤—
          </span>
          <span>Demo</span>
        </a>
      </div>
    </div>
  </div>
</section>



<section class="section" id="abstract">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <video id="abstract_video" controls autoplay muted loop width="100%">
        <source src="./static/assets/demo.mp4"
                type="video/mp4">
          </video>
      </div>
    </div>
  </div>
</section>


<section class="section" id="abstract">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Abstract</h2>
        <video id="abstract_video" autoplay muted loop width="100%">
        <source src="./static/assets/abs2.mp4"
                type="video/mp4">
          </video>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <h2 class="subheader">We introduce CoVLM, a novel vision-language model able to compose visual entities and relationships via communicative decoding. </h2>
    </div>
    <div class="column is-full-width">
      <p>CoVLM is specifically designed to guide the LLM to explicitly <strong>compose visual entities and relationships</strong> among the text and dynamically communicate with the vision encoder and detection network to achieve <strong>vision-language communicative decoding</strong>. Specifically, we first devise a set of novel <strong>communication tokens</strong> for the LLM, for dynamic communication between the visual detection system and the language system. A communication token is generated by LLM to inform the detection network to propose <strong>relevant regions</strong> that LLM should pay attention to. The proposed regions-of-interests (ROIs) are then fed back into the LLM for better language generation <strong>contingent on the relevant regions</strong>.</p>
    </div>
    <div class="columns is-vcentered is-centered">
      <video id="teaser" autoplay muted loop width="80%">
        <source src="./static/assets/method.mp4"
            type="video/mp4">
      </video>
      </br>
    </div>
    <div class="column is-full-width">
      <p>We hope CoVLM inspires more advancements in compositional reasoning ability for LLM, making machine more intelligent in broader applications.</p>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<!-- 

<div class="container is-max-desktop" id="motivation">
  <hr class="solid">
</div>

<section class="hero">
  <div class="container is-fullhd">
    <div class="column is-full-width is-centered has-text-centered">
      <h2 class="title is-3">Motivation</h2>
    </div>
  </div>
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="columns is-centered has-text-centered" style="margin-top: 20px;">
        <h2 class="title is-4" style="width: 70%;">The motivation is derived from human's intrinsic ability: compose what we see for better understanding. </h2>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <image src="./static/assets/motivation.png" width="100%" style="margin-top: 20px;">
      </div>
    </div>
  </div>
</section>  -->


<div class="container is-max-desktop">
  <hr class="solid">
  <div class="column is-full-width is-centered has-text-centered">
    <h2 class="title is-3">Qualitative Results</h2>
  </div>
</div>




<section class="hero" id="qualitative">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-vcentered  is-centered">
          <img src="./static/assets/comp1.png" width="100%">
          </br>
        </div>
        <div class="container is-max-desktop">
          <hr class="solid">
        </div>
        <div class="columns is-vcentered  is-centered">
          <img src="./static/assets/comp2.png" width="100%">
          </br>
        </div>
        <div class="container is-max-desktop">
          <hr class="solid">
        </div>
        <div class="columns is-vcentered  is-centered">
          <img src="./static/assets/comp3.png" width="100%">
          </br>
        </div>
        <div class="container is-max-desktop">
          <hr class="solid">
        </div>
        <div class="columns is-vcentered  is-centered">
          <img src="./static/assets/comp4.png" width="100%">
          </br>
        </div>
        <br>
      </div>
    </div>
  </div>
</section>


<!-- <div class="container is-max-desktop" id="dataset">
  <hr class="solid">
</div> -->
<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Dataset</h2>
        <div class="content has-text-justified">
          <p>
            For multimodal pre-training, we create a large-scale grounded image-text dataset which consists of over 97M
            image-text pairs from the pre-training data of BLIP-2. We apply a grounding pipeline to the image-text pair
            to associate the text spans in the caption to their corresponding visual entities in the image. The
            pipeline consists of three steps:
          </p>
        </div>
      </div>
    </div>

    <div class="card">
      <header class="card-header">
        <p class="card-header-title">
          Step 1: Generating bounding-box-word pairs
        </p>
      </header>
      <div class="card-content">
        <div class="content">
          We use GroundingDINO to detect objects in the image and link the bounding box of the object to words in the text.
        </div>
      </div>
    </div>


    <div class="card">
      <header class="card-header">
        <p class="card-header-title">
          Step 2: Expanding grounded words to grounded expressions
        </p>
      </header>
      <div class="card-content">
        <div class="content">
          Inspired by KOSMOS-2, we apply spaCy to obtain each word's dependency relation in the sentence, and expand a grounded word to a grounded expression by recursively traversing the dependency tree of that word and concatenate eligible children words based on the linguistic rules.
        </div>
      </div>
    </div>


    <div class="card">
      <header class="card-header">
        <p class="card-header-title">
          Step 3: Assigning bounding boxes to the special communication tokens
        </p>
      </header>
      <div class="card-content">
        <div class="content">
          Given the expressions and their associated bounding boxes in a grounded image-text pair, we can now insert the special communication tokens into the text and assign the bounding boxes to them
        </div>
      </div>
    </div>
  </div>
</section> -->


<!-- <div class="container is-max-desktop" id="results">
  <hr class="solid">
  <div class="column is-full-width is-centered has-text-centered">
    <h2 class="title is-3">Results</h2>
    <p>click to expand</p>
  </div>
</div> -->

<!-- 
<section class="section">
  <div class="container is-max-desktop" style="margin-top: 20px;">
    <div class="card">
      <header class="card-header">
        <p class="card-header-title card-toggle">
          Compositional Entity Prediction
        </p>
        <a class="card-header-icon card-toggle">
          <i class="fa fa-angle-down"></i>
        </a>
      </header>
      <div class="card-content is-hidden">
        <canvas id="aro_chart" style="width:100%;"></canvas>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop" style="margin-top: 20px;">
    <div class="card">
      <header class="card-header">
        <p class="card-header-title card-toggle">
          Compositional Text-to-image Retrieval
        </p>
        <a class="card-header-icon card-toggle">
          <i class="fa fa-angle-down"></i>
        </a>
      </header>
      <div class="card-content is-hidden">
        <canvas id="cola_chart" style="width:100%;"></canvas>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop" style="margin-top: 20px;">
    <div class="card">
      <header class="card-header">
        <p class="card-header-title card-toggle">
          Human-Object Interaction Detection
        </p>
        <a class="card-header-icon card-toggle">
          <i class="fa fa-angle-down"></i>
        </a>
      </header>
      <div class="card-content is-hidden">
        <canvas id="hico_chart" style="width:100%;"></canvas>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop" style="margin-top: 20px;">
    <div class="card">
      <header class="card-header">
        <p class="card-header-title card-toggle">
          Referring Expression Comprehension
        </p>
        <a class="card-header-icon card-toggle">
          <i class="fa fa-angle-down"></i>
        </a>
      </header>
      <div class="card-content is-hidden">
        <canvas id="refcoco_chart" style="width:100%;"></canvas>
      </div>
    </div>
  </div>

  <div class="container is-max-desktop" style="margin-top: 20px;">
    <div class="card">
      <header class="card-header">
        <p class="card-header-title card-toggle">
          Visual Question Answering
        </p>
        <a class="card-header-icon card-toggle">
          <i class="fa fa-angle-down"></i>
        </a>
      </header>
      <div class="card-content is-hidden">
        <canvas id="vqa_chart" style="width:100%;"></canvas>
      </div>
    </div>
  </div>
</section> -->


<script
src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.4/Chart.js">
</script>

<script>
  const xValues = ["MetaLM", "VLKD", "OpenFlamingo3B", "Flamingo3B", "BLIP-2 ViT-L OPT-2.7B", "KOSMOS-2", "Ours 1.4B", "Ours 2.8B"];
  const yValues = [41.1, 44.5, 44.6, 49.2, 49.7, 45.6, 45.2, 48.8];
  const barColors = ["red", "green", "yellow", "orange", "brown", "pink", "blue", "purple"];
  
  new Chart("vqa_chart", {
    type: "bar",
    data: {
      labels: xValues,
      datasets: [{
        backgroundColor: barColors,
        data: yValues
      }]
    },
    options: {
      legend: {display: false},
      title: {
        display: true,
        text: "VQAv2 Test-dev Zero-shot Accuracy (%)"
      }
    }
  });
</script>


<script>
  const refcoco_xValues =  ["ReCLIP", "KOSMOS-2", "Ours 1.4B", "Ours 2.8B"];
  const refcocog_yValues = [59.33, 60.57, 60.87, 61.23];
  const refcocop_yValues = [47.87, 45.48, 47.62, 48.87];
  const refcoco_yValues =  [45.78, 52.32, 48.19, 49.32];

  new Chart("refcoco_chart", {
    type: "bar",
    data: {
      labels: refcoco_xValues,
      datasets: [
          {
            label: "RefCOCOg",
            backgroundColor: "blue",
            data: refcocog_yValues
          },
          {
            label: "RefCOCO+",
            backgroundColor: "red",
            data: refcocop_yValues
          },
          {
            label: "RefCOCO",
            backgroundColor: "purple",
            data: refcoco_yValues
          },
      ]
    },
    options: {
      legend: {display: false},
      title: {
        display: true,
        text: "Referring Expression Comprehension Zero-shot Accuracy (%)"
      }
    }
  });
</script>



<script>
  const hico_xValues =  ["RLIPv1-ParSe", "RLIPv2-ParSeDA", "KOSMOS-2", "Ours 1.4B"];
  const rare_yValues =    [15.08, 27.97, 33.51, 50.82];
  const nonrare_yValues = [15.50, 21.90, 17.83, 35.47];
  const full_yValues =    [15.40, 23.29, 21.26, 39.00];

  new Chart("hico_chart", {
    type: "bar",
    data: {
      labels: hico_xValues,
      datasets: [
          {
            label: "Rare",
            backgroundColor: "blue",
            data: rare_yValues
          },
          {
            label: "Non-Rare",
            backgroundColor: "red",
            data: nonrare_yValues
          },
          {
            label: "Full",
            backgroundColor: "purple",
            data: full_yValues
          },
      ]
    },
    options: {
      legend: {display: false},
      title: {
        display: true,
        text: "HICO-DET Zero-shot mAP (%)"
      }
    }
  });
</script>




<script>
  const cola_xValues = ["CLIP", "FLAVA", "OpenFlamingo3B", "BLIP", "BLIP-2 ViT-L OPT-2.7B", "KOSMOS-2", "Ours 1.4B"];
  const cola_yValues = [21.42, 24.76, 18.10, 41.43, 35.71, 30.48, 44.29];
  const cola_barColors = ["red", "green", "yellow", "orange", "brown", "pink", "blue"];
  
  new Chart("cola_chart", {
    type: "bar",
    data: {
      labels: cola_xValues,
      datasets: [{
        backgroundColor: cola_barColors,
        data: cola_yValues
      }]
    },
    options: {
      legend: {display: false},
      title: {
        display: true,
        text: "Cola Zero-shot Accuracy (%)"
      }
    }
  });
</script>



<script>
  const aro_xValues =  ["CLIP", "FLAVA", "OpenFlamingo3B", "BLIP", "BLIP-2 ViT-L OPT-2.7B", "KOSMOS-2", "Ours 1.4B"];
  const aro1_yValues = [6.93, 4.59, 2.55, 29.78, 29.73, 19.88, 32.46];
  const aro5_yValues = [21.12, 12.76, 7.11, 54.18, 54.91, 43.69, 55.70];

  new Chart("aro_chart", {
    type: "bar",
    data: {
      labels: aro_xValues,
      datasets: [
          {
            label: "Top-1 Accuracy",
            backgroundColor: "blue",
            data: aro1_yValues
          },
          {
            label: "Top-5 Accuracy",
            backgroundColor: "red",
            data: aro5_yValues
          },
      ]
    },
    options: {
      legend: {display: false},
      title: {
        display: true,
        text: "ARO Entity Prediction Zero-shot Accuracy (%)"
      }
    }
  });
</script>


<script>
  document.addEventListener('DOMContentLoaded', function() {
    let cardToggles = document.getElementsByClassName('card-toggle');
    for (let i = 0; i < cardToggles.length; i++) {
      cardToggles[i].addEventListener('click', e => {
        e.currentTarget.parentElement.parentElement.childNodes[3].classList.toggle('is-hidden');
      });
    }
  });
</script>


<script>
  // const collapsibles = document.querySelectorAll('.collapsible');
  // collapsibles.forEach(collapsible => {
  //   const content = collapsible.nextElementSibling;
  //   collapsible.addEventListener('click', () => {
  //     content.classList.toggle('active'); 
  //     if (content.style.display === "block") {
  //       content.style.display = "none";
  //     } else {
  //       content.style.display = "block";
  //     }     
  //     if (content.classList.contains('active')) {
  //       videos.forEach(video => {
  //         video.src = video.getAttribute('data-src');
  //       });
  //     }
  //   });
  // });
  // Get the button and content elements
  const collapsibles = document.querySelectorAll('.collapsible');
    collapsibles.forEach(collapsible => {
    const content = collapsible.nextElementSibling;

    // Add an event listener to the button to toggle the content
    collapsible.addEventListener('click', function() {
      this.classList.toggle("active");
      if (content.style.display === 'block') {
        content.style.display = 'none';
        this.innerHTML = "Click to show videos";
      } else {
        content.style.display = 'block';
        this.innerHTML = "Click to hide videos";
        
        // Find all the video elements within the content
        const videos = content.querySelectorAll('video');
        
        // Set the src attribute of each video element
        videos.forEach(video => {
          if (!video.loaded) {
            const videoSrc = video.getAttribute('data-src');
            if (videoSrc) {
              video.src = videoSrc;
              video.loaded = true;
            }
          }
        });
      }
    });
  });
// var buttons = document.querySelectorAll('.collapsible');

// // Loop through the buttons and add a click event listener to each one
// for (var i = 0; i < buttons.length; i++) {
//   buttons[i].addEventListener('click', function() {

//     // Get the content element that corresponds to this button
//     var content = this.nextElementSibling;
//     const videos = content.querySelectorAll('video');


//     buttons[i].addEventListener('click', () => {
//       content.classList.toggle('active');
//     });
//     if (content.style.display === "block") {
//       content.style.display = "none";
//     } else {
//       content.style.display = "block";
//     }

//   });
// }

</script>


<!-- Default Statcounter code for compositionalvlm
https://compositionalvlm.github.io/ -->
<script type="text/javascript">
  var sc_project=12930260; 
  var sc_invisible=1; 
  var sc_security="f93f9c3b"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img class="statcounter"
  src="https://c.statcounter.com/12930260/0/f93f9c3b/1/" alt="Web Analytics"
  referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
  <!-- End of Statcounter Code -->

</body>
</html>
