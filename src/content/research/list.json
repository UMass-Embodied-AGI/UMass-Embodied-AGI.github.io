[
  {
    "id": "li2024flexattentionefficienthighresolutionvisionlanguage",
    "type": "misc",
    "title": "FlexAttention for Efficient High-Resolution Vision-Language Models",
    "authors": [
      "Junyan Li",
      "Delin Chen",
      "Tianle Cai",
      "Peihao Chen",
      "Yining Hong",
      "Zhenfang Chen",
      "Yikang Shen",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2407.20228",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/flexattention/index.html",
    "website": "/research/flexattention/index.html",
    "code": "https://github.com/UMass-Embodied-AGI/FlexAttention",
    "arxiv": "https://arxiv.org/abs/2407.20228",
    "preview": "/research/flexattention/static/assets/overview.jpg",
    "category": "Large Language Models",
    "conference": "ECCV 2024"
  },
  {
    "id": "wang2024robogenunleashinginfinitedata",
    "type": "misc",
    "title": "RoboGen: Towards Unleashing Infinite Data for Automated Robot Learning via Generative Simulation",
    "authors": [
      "Yufei Wang",
      "Zhou Xian",
      "Feng Chen",
      "Tsun-Hsuan Wang",
      "Yian Wang",
      "Katerina Fragkiadaki",
      "Zackory Erickson",
      "David Held",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2311.01455",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.RO",
    "url": "https://arxiv.org/abs/2311.01455",
    "preview": "https://robogen-ai.github.io/videos/trailer.mp4",
    "pdf": "https://arxiv.org/pdf/2311.01455",
    "arxiv": "https://arxiv.org/abs/2311.01455",
    "website": "https://robogen-ai.github.io/",
    "booktitle": "International conference on machine learning",
    "code": "https://github.com/Genesis-Embodied-AI/RoboGen",
    "selected": true,
    "category": "Physical Reasoning and Interaction",
    "conference": "ICML 2024"
  },
  {
    "id": "li2024conavbenchmarkhumancenteredcollaborative",
    "type": "misc",
    "title": "CoNav: A Benchmark for Human-Centered Collaborative Navigation",
    "authors": [
      "Changhao Li",
      "Xinyu Sun",
      "Peihao Chen",
      "Jugang Fan",
      "Zixu Wang",
      "Yanxia Liu",
      "Jinhui Zhu",
      "Chuang Gan",
      "Mingkui Tan"
    ],
    "year": "2024",
    "eprint": "2406.02425",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2406.02425",
    "arxiv": "https://arxiv.org/abs/2406.02425",
    "category": "Physical Reasoning and Interaction",
    "code": "https://github.com/Li-ChangHao/CoNav",
    "preview": "https://github.com/Li-ChangHao/CoNav/raw/main/assets/lustration.png"
  },
  {
    "id": "zhou2024robodreamerlearningcompositionalworld",
    "type": "misc",
    "title": "RoboDreamer: Learning Compositional World Models for Robot Imagination",
    "authors": [
      "Siyuan Zhou",
      "Yilun Du",
      "Jiaben Chen",
      "Yandong Li",
      "Dit-Yan Yeung",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2404.12377",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.RO",
    "url": "/research/robodreamer/index.html",
    "website": "/research/robodreamer/index.html",
    "arxiv": "https://arxiv.org/abs/2404.12377",
    "preview": "/research/robodreamer/method.png",
    "category": "Physical Reasoning and Interaction"
  },
  {
    "id": "zhang2024combocompositionalworldmodels",
    "type": "misc",
    "title": "COMBO: Compositional World Models for Embodied Multi-Agent Cooperation",
    "authors": [
      "Hongxin Zhang",
      "Zeyuan Wang",
      "Qiushi Lyu",
      "Zheyuan Zhang",
      "Sunli Chen",
      "Tianmin Shu",
      "Yilun Du",
      "Chuang Gan"
    ],
    "year": "2025",
    "eprint": "2404.10775",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/combo/index.html",
    "website": "/research/combo/index.html",
    "code": "https://github.com/UMass-Embodied-AGI/COMBO",
    "arxiv": "https://arxiv.org/abs/2404.10775",
    "preview": "/research/combo/video/teaser.mp4",
    "category": "Physical Reasoning and Interaction",
    "conference": "ICLR 2025"
  },
  {
    "id": "Chen2024VisualCP",
    "type": "inproceedings",
    "title": "Visual Chain-of-Thought Prompting for Knowledge-Based Visual Reasoning",
    "authors": [
      "Zhenfang Chen",
      "Qinhong Zhou",
      "Yikang Shen",
      "Yining Hong",
      "Zhiqing Sun",
      "Dan Gutfreund",
      "Chuang Gan"
    ],
    "booktitle": "AAAI Conference on Artificial Intelligence",
    "year": "2024",
    "url": "https://api.semanticscholar.org/CorpusID:268678279",
    "code": "https://github.com/UMass-Embodied-AGI/VisualCoT",
    "arxiv": "https://arxiv.org/abs/2404.00451",
    "preview": "https://github.com/UMass-Embodied-AGI/VisualCoT/raw/main/framework.png",
    "category": "Multimodal Language Models",
    "conference": "AAAI 2024"
  },
  {
    "id": "yang20243dmem3dscenememory",
    "type": "misc",
    "title": "3D-Mem: 3D Scene Memory for Embodied Exploration and Reasoning",
    "authors": [
      "Yuncong Yang",
      "Han Yang",
      "Jiachen Zhou",
      "Peihao Chen",
      "Hongxin Zhang",
      "Yilun Du",
      "Chuang Gan"
    ],
    "year": "2025",
    "eprint": "2411.17735",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/3dmem/index.html",
    "website": "/research/3dmem/index.html",
    "code": "https://github.com/UMass-Foundation-Model/3D-Mem",
    "arxiv": "https://arxiv.org/abs/2411.17735",
    "preview": "/demo/3DMem_opening.mp4",
    "category": "Multimodal Language Models",
    "conference": "CVPR 2025"
  },
  {
    "id": "zhen20243dvla3dvisionlanguageactiongenerative",
    "type": "misc",
    "title": "3D-VLA: A 3D Vision-Language-Action Generative World Model",
    "authors": [
      "Haoyu Zhen",
      "Xiaowen Qiu",
      "Peihao Chen",
      "Jincheng Yang",
      "Xin Yan",
      "Yilun Du",
      "Yining Hong",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2403.09631",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/3dvla/index.html",
    "preview": "/research/3dvla/static/video/demo.mp4",
    "booktitle": "International conference on machine learning",
    "selected": true,
    "website": "/research/3dvla/index.html",
    "arxiv": "https://arxiv.org/abs/2403.09631",
    "pdf": "https://arxiv.org/pdf/2403.09631",
    "code": "https://github.com/UMass-Foundation-Model/3D-VLA",
    "category": "Learning World Models",
    "conference": "ICML 2024"
  },
  {
    "id": "sun2024salmonselfalignmentinstructablereward",
    "type": "misc",
    "title": "SALMON: Self-Alignment with Instructable Reward Models",
    "authors": [
      "Zhiqing Sun",
      "Yikang Shen",
      "Hongxin Zhang",
      "Qinhong Zhou",
      "Zhenfang Chen",
      "David Cox",
      "Yiming Yang",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2310.05910",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CL",
    "url": "https://arxiv.org/abs/2310.05910",
    "code": "https://github.com/IBM/SALMON",
    "arxiv": "https://arxiv.org/abs/2310.05910",
    "preview": "https://github.com/IBM/SALMON/raw/main/assets/images/salmon_logo_with_text.jpeg",
    "category": "Large Language Models",
    "conference": "ICLR 2024"
  },
  {
    "id": "wang2024thinshellobjectmanipulationsdifferentiable",
    "type": "misc",
    "title": "Thin-Shell Object Manipulations With Differentiable Physics Simulations",
    "authors": [
      "Yian Wang",
      "Juntian Zheng",
      "Zhehuan Chen",
      "Zhou Xian",
      "Gu Zhang",
      "Chao Liu",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2404.00451",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.RO",
    "url": "/research/ThinShellLab/index.html",
    "website": "/research/ThinShellLab/index.html",
    "code": "https://github.com/wangyian-me/ThinShellLab",
    "arxiv": "https://arxiv.org/abs/2404.00451",
    "preview": "https://wangyian-me.github.io/images/thinshelllabgif.gif",
    "category": "Physical Reasoning and Interaction",
    "conference": "ICLR 2024"
  },
  {
    "id": "zhang2024buildingcooperativeembodiedagents",
    "type": "misc",
    "title": "Building Cooperative Embodied Agents Modularly with Large Language Models",
    "authors": [
      "Hongxin Zhang",
      "Weihua Du",
      "Jiaming Shan",
      "Qinhong Zhou",
      "Yilun Du",
      "Joshua B. Tenenbaum",
      "Tianmin Shu",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2307.02485",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.AI",
    "url": "/research/Co-LLM-Agents/index.html",
    "website": "/research/Co-LLM-Agents/index.html",
    "arxiv": "https://arxiv.org/abs/2411.17735",
    "preview": "/research/Co-LLM-Agents/figure/teaser_v1.7.jpg",
    "category": "Multimodal Language Models",
    "conference": "ICLR 2024"
  },
  {
    "id": "zhou2024hazardchallengeembodieddecision",
    "type": "misc",
    "title": "HAZARD Challenge: Embodied Decision Making in Dynamically Changing Environments",
    "authors": [
      "Qinhong Zhou",
      "Sunli Chen",
      "Yisong Wang",
      "Haozhe Xu",
      "Weihua Du",
      "Hongxin Zhang",
      "Yilun Du",
      "Joshua B. Tenenbaum",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2401.12975",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/hazard/index.html",
    "website": "/research/hazard/index.html",
    "code": "https://github.com/UMass-Embodied-AGI/HAZARD",
    "arxiv": "https://arxiv.org/abs/2411.17735",
    "preview": "https://github.com/UMass-Embodied-AGI/HAZARD/blob/main/pics/overview.png?raw=true",
    "category": "Physical Reasoning and Interaction",
    "conference": "ICLR 2024"
  },
  {
    "id": "chen2023genomegenerativeneurovisual",
    "type": "misc",
    "title": "GENOME: GenerativE Neuro-symbOlic visual reasoning by growing and reusing ModulEs",
    "authors": [
      "Zhenfang Chen",
      "Rui Sun",
      "Wenjun Liu",
      "Yining Hong",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2311.04901",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/genome/index.html",
    "website": "/research/genome/index.html",
    "code": "https://github.com/UMass-Embodied-AGI/genome",
    "arxiv": "https://arxiv.org/abs/2311.04901",
    "doi": "10.48550/arXiv.2311.04901",
    "preview": "/research/genome/GNSVR_files/11_imgedit.gif",
    "category": "Learning World Models",
    "conference": "ICLR 2024"
  },
  {
    "id": "si2024DiffTactile",
    "type": "misc",
    "title": "DiffTactile: A Physics-based Differentiable Tactile Simulator for Contact-rich Robotic Manipulation",
    "authors": [
      "Zilin Si",
      "Gu Zhang",
      "Qingwei Ben",
      "Branden Romero",
      "Zhou Xian",
      "Chao Liu",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2403.08716",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://difftactile.github.io/",
    "website": "https://difftactile.github.io/",
    "code": "https://github.com/Genesis-Embodied-AI/DiffTactile",
    "arxiv": "https://arxiv.org/abs/2403.08716",
    "doi": "10.48550/arXiv.2403.08716",
    "preview": "/research/difftactile/difftactile.gif",
    "category": "Learning World Models",
    "conference": "ICLR 2024"
  },
  {
    "id": "li2023covlmcomposingvisualentities",
    "type": "misc",
    "title": "CoVLM: Composing Visual Entities and Relationships in Large Language Models Via Communicative Decoding",
    "authors": [
      "Junyan Li",
      "Delin Chen",
      "Yining Hong",
      "Zhenfang Chen",
      "Peihao Chen",
      "Yikang Shen",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2311.03354",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/CoVLM/index.html",
    "website": "/research/CoVLM/index.html",
    "code": "https://github.com/UMass-Embodied-AGI/CoVLM",
    "arxiv": "https://arxiv.org/abs/2311.03354",
    "preview": "/research/CoVLM/static/assets/demo.mp4",
    "category": "Large Language Models",
    "conference": "ICLR 2024"
  },
  {
    "id": "cai2024efficientvitmultiscalelinearattention",
    "type": "misc",
    "title": "EfficientViT: Multi-Scale Linear Attention for High-Resolution Dense Prediction",
    "authors": ["Han Cai", "Junyan Li", "Muyan Hu", "Chuang Gan", "Song Han"],
    "year": "2023",
    "eprint": "2205.14756",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2205.14756",
    "arxiv": "https://arxiv.org/abs/2411.17735",
    "preview": "https://senfu.github.io/images/efficientvit/intro.png",
    "conference": "ICCV 2023",
    "category": "Large Language Models"
  },
  {
      "id": "du2024constrainedhumanaicooperation",
      "type": "misc",
      "title": "Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge",
      "authors": [
        "Weihua Du",
        "Qiushi Lyu",
        "Jiaming Shan",
        "Zhenting Qi", 
        "Hongxin Zhang",
        "Sunli Chen",
        "Andi Peng",
        "Tianmin Shu",
        "Kwonjoon Lee",
        "Behzad Dariush",
        "Chuang Gan"
      ],
      "year": "2024",
      "eprint": "2411.01796",
      "archiveprefix": "arXiv",
      "primaryclass": "cs.AI",
      "url": "/research/CHAIC/index.html",
      "website": "/research/CHAIC/index.html",
      "arxiv": "https://arxiv.org/abs/2411.01796",
      "preview": "/research/CHAIC/figure/teaser_v4.png",
      "category": "Physical Reasoning and Interaction",
      "conference": "NeurIPS 2024"
  },
  {
    "id": "nguyen2024open3disopenvocabulary",
    "type": "misc",
    "title": "Open3DIS: Open-Vocabulary 3D Instance Segmentation with 2D Mask Guidance",
    "authors": [
      "Phuc D.A. Nguyen",
      "Tuan Duc Ngo",
      "Evangelos Kalogerakis",
      "Chuang Gan",
      "Cuong Pham",
      "Khoi Nguyen"
    ],
    "year": "2024",
    "eprint": "2312.10671",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.AI",
    "url": "https://open3dis.github.io/assets/2312.10671.pdf",
    "website": "https://open3dis.github.io/",
    "arxiv": "https://arxiv.org/abs/2312.10671",
    "preview": "/research/Open3DIS/preview.png",
    "category": "Learning World Models",
    "conference": "CVPR 2024"
  },
  {
    "id": "wang2024sokbenchasituatedvideoreasoning",
    "type": "misc",
    "title": "SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World Knowledge",
    "authors": [
      "Andong Wang",
      "Bo Wu",
      "Sunli Chen",
      "Zhenfang Chen",
      "Wei-Ning Lee",
      "Li Erran Li",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2405.09713",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.AI",
    "url": "https://openaccess.thecvf.com/content/CVPR2024/html/Wang_SOK-Bench_A_Situated_Video_Reasoning_Benchmark_with_Aligned_Open-World_Knowledge_CVPR_2024_paper.html",
    "website": "https://bobbywu.com/SOKBench/",
    "arxiv": "https://arxiv.org/abs/2405.09713",
    "preview": "/research/SOK/preview.png",
    "category": "Multimodal Language Models",
    "conference": "CVPR 2024"
  },
  {
    "id": "yang2024rilareflectiveandimaginative",
    "type": "misc",
    "title": "RILA: Reflective and Imaginative Language Agent for Zero-Shot Semantic Audio-Visual Navigation",
    "authors": [
      "Zeyuan Yang",
      "Jiageng Liu",
      "Peihao Chen",
      "Anoop Cherian",
      "Tim K Marks",
      "Jonathan Le Roux",
      "Chuang Gan"
    ],
    "year": "2024",
    "url": "https://openaccess.thecvf.com/content/CVPR2024/html/Yang_RILA_Reflective_and_Imaginative_Language_Agent_for_Zero-Shot_Semantic_Audio-Visual_CVPR_2024_paper.html",
    "preview": "/research/RILA/preview.png",
    "category": "Vision Learning & Navigation",
    "conference": "CVPR 2024"
  },
  {
    "id": "hong2024multiplymultisensoryobjectcentricembodied",
    "type": "misc",
    "title": "MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in 3D World",
    "authors": [
      "Yining Hong",
      "Zishuo Zheng",
      "Peihao Chen",
      "Yian Wang",
      "Junyan Li",
      "Chuang Gan"
    ],
    "year": "2024",
    "eprint": "2401.08577",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/multiply/index.html",
    "website": "/research/multiply/index.html",
    "code": "https://github.com/UMass-Embodied-AGI/MultiPLY",
    "arxiv": "https://arxiv.org/abs/2401.08577",
    "preview": "/research/multiply/resources/cd_player.mp4",
    "category": "Audio-Visual Learning"
  },
  {
    "id": "gu2024conceptgraphs",
    "type": "misc",
    "title": "ConceptGraphs: Open-Vocabulary 3D Scene Graphs for Perception and Planning",
    "authors": [
      "Qiao Gu",
      "Alihusein Kuwajerwala",
      "Sacha Morin",
      "Krishna Murthy Jatavallabhula",
      "Bipasha Sen",
      "Aditya Agarwal",
      "Corban Rivera",
      "William Paul",
      "Kirsty Ellis",
      "Rama Chellappa",
      "Chuang Gan",
      "Celso Miguel de Melo",
      "Joshua B. Tenenbaum",
      "Antonio Torralba",
      "Florian Shkurti",
      "Liam Paull"
    ],
    "year": "2024",
    "eprint": "2309.16650",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.RO",
    "url": "https://concept-graphs.github.io/",
    "website": "https://concept-graphs.github.io/",
    "code": "https://github.com/concept-graphs/concept-graphs",
    "arxiv": "https://arxiv.org/abs/2309.16650",
    "preview": "https://concept-graphs.github.io/static/images/pipeline.png",
    "category": "Vision Learning & Navigation",
    "conference": "ICRA 2024"
  },
  {
    "id": "hong20233dconceptlearningreasoning",
    "type": "misc",
    "title": "3D Concept Learning and Reasoning from Multi-View Images",
    "authors": [
      "Yining Hong",
      "Chunru Lin",
      "Yilun Du",
      "Zhenfang Chen",
      "Joshua B. Tenenbaum",
      "Chuang Gan"
    ],
    "year": "2023",
    "eprint": "2303.11327",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/3d-clr/index.html",
    "website": "/research/3d-clr/index.html",
    "arxiv": "https://arxiv.org/abs/2303.11327",
    "doi": "10.48550/arXiv.2303.11327",
    "preview": "/research/3d-clr/materials/3d-cg2.png",
    "category": "Learning World Models"
  },
  {
    "id": "lin2023dcirdynamicconsistencyintrinsic",
    "type": "misc",
    "title": "DCIR: Dynamic Consistency Intrinsic Reward for Multi-Agent Reinforcement Learning",
    "authors": [
      "Kunyang Lin",
      "Yufeng Wang",
      "Peihao Chen",
      "Runhao Zeng",
      "Siyuan Zhou",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2023",
    "eprint": "2312.05783",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.LG",
    "url": "https://arxiv.org/abs/2312.05783",
    "arxiv": "https://arxiv.org/abs/2312.05783",
    "category": "Large Language Models"
  },
  {
    "id": "sun2023principledrivenselfalignmentlanguagemodels",
    "type": "article",
    "title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision",
    "authors": [
      "Zhiqing Sun",
      "Yikang Shen",
      "Qinhong Zhou",
      "Hongxin Zhang",
      "Zhenfang Chen",
      "David Cox",
      "Yiming Yang",
      "Chuang Gan"
    ],
    "year": "2023",
    "eprint": "2305.03047",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.LG",
    "url": "https://arxiv.org/abs/2305.03047",
    "selected": true,
    "website": "https://github.com/IBM/Dromedary",
    "preview": "https://github.com/IBM/Dromedary/raw/main/assets/images/dromedary_logo_with_text.svg",
    "pdf": "https://arxiv.org/pdf/2305.03047",
    "arxiv": "https://arxiv.org/abs/2305.03047",
    "code": "https://github.com/IBM/Dromedary",
    "journal": "Advances in Neural Information Processing Systems",
    "category": "Large Language Models"
  },
  {
    "id": "chen2023a2navactionawarezeroshotrobot",
    "type": "misc",
    "title": "A^2Nav: Action-Aware Zero-Shot Robot Navigation by Exploiting Vision-and-Language Ability of Foundation Models",
    "authors": [
      "Peihao Chen",
      "Xinyu Sun",
      "Hongyan Zhi",
      "Runhao Zeng",
      "Thomas H. Li",
      "Gaowen Liu",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2023",
    "eprint": "2308.07997",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2308.07997",
    "arxiv": "https://arxiv.org/abs/2308.07997",
    "category": "Physical Reasoning and Interaction"
  },
  {
    "id": "lin2023learningvisionandlanguagenavigationyoutube",
    "type": "misc",
    "title": "Learning Vision-and-Language Navigation from YouTube Videos",
    "authors": [
      "Kunyang Lin",
      "Peihao Chen",
      "Diwei Huang",
      "Thomas H. Li",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2023",
    "eprint": "2307.11984",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2307.11984",
    "arxiv": "https://arxiv.org/abs/2307.11984",
    "preview": "https://github.com/JeremyLinky/YouTube-VLN/raw/main/readme/lily.png",
    "category": "Vision Learning & Navigation"
  },
  {
    "id": "hong20233dllminjecting3dworld",
    "type": "article",
    "title": "3D-LLM: Injecting the 3D World into Large Language Models",
    "authors": [
      "Yining Hong",
      "Haoyu Zhen",
      "Peihao Chen",
      "Shuhong Zheng",
      "Yilun Du",
      "Zhenfang Chen",
      "Chuang Gan"
    ],
    "year": "2023",
    "eprint": "2307.12981",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/3dllm/index.html",
    "selected": true,
    "arxiv": "https://arxiv.org/abs/2307.12981",
    "code": "https://github.com/umass-foundation-model/3d-llm",
    "preview": "/research/3dllm/data/new_chat_demo.mp4",
    "website": "/research/3dllm/index.html",
    "pdf": "https://arxiv.org/pdf/2307.12981",
    "journal": "Advances in Neural Information Processing Systems",
    "category": "Multimodal Language Models"
  },
  {
    "id": "sun2023maskedmotionencodingselfsupervised",
    "type": "misc",
    "title": "Masked Motion Encoding for Self-Supervised Video Representation Learning",
    "authors": [
      "Xinyu Sun",
      "Peihao Chen",
      "Liangwei Chen",
      "Changhao Li",
      "Thomas H. Li",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2023",
    "eprint": "2210.06096",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2210.06096",
    "arxiv": "https://arxiv.org/abs/2210.06096",
    "preview": "https://github.com/XinyuSun/MME/raw/main/resource/arch.png",
    "category": "Vision Learning & Navigation"
  },
  {
    "id": "chen2022modsquaddesigningmixtureexperts",
    "type": "misc",
    "title": "Mod-Squad: Designing Mixture of Experts As Modular Multi-Task Learners",
    "authors": [
      "Zitian Chen",
      "Yikang Shen",
      "Mingyu Ding",
      "Zhenfang Chen",
      "Hengshuang Zhao",
      "Erik Learned-Miller",
      "Chuang Gan"
    ],
    "year": "2022",
    "eprint": "2212.08066",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "/research/mod-squad/index.html",
    "website": "/research/mod-squad/index.html",
    "arxiv": "https://arxiv.org/abs/2212.08066",
    "doi": "10.48550/arXiv.2212.08066",
    "preview": "/research/mod-squad/materials/annimation.mp4",
    "category": "Multimodal Language Models"
  },
  {
    "id": "chen2022learningactivecameramultiobject",
    "type": "misc",
    "title": "Learning Active Camera for Multi-Object Navigation",
    "authors": [
      "Peihao Chen",
      "Dongyu Ji",
      "Kunyang Lin",
      "Weiwen Hu",
      "Wenbing Huang",
      "Thomas H. Li",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2022",
    "eprint": "2210.07505",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2210.07505",
    "arxiv": "https://arxiv.org/abs/2210.07505",
    "category": "Physical Reasoning and Interaction"
  },
  {
    "id": "chen2022weaklysupervisedmultigranularitymaplearning",
    "type": "misc",
    "title": "Weakly-Supervised Multi-Granularity Map Learning for Vision-and-Language Navigation",
    "authors": [
      "Peihao Chen",
      "Dongyu Ji",
      "Kunyang Lin",
      "Runhao Zeng",
      "Thomas H. Li",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2022",
    "eprint": "2210.07506",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2210.07506",
    "arxiv": "https://arxiv.org/abs/2210.07506",
    "category": "Physical Reasoning and Interaction"
  },
  {
    "id": "chen2021rspnetrelativespeedperception",
    "type": "misc",
    "title": "RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning",
    "authors": [
      "Peihao Chen",
      "Deng Huang",
      "Dongliang He",
      "Xiang Long",
      "Runhao Zeng",
      "Shilei Wen",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2021",
    "eprint": "2011.07949",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2011.07949",
    "arxiv": "https://arxiv.org/abs/2011.07949",
    "category": "Vision Learning & Navigation"
  },
  {
    "id": "8933113",
    "type": "article",
    "title": "Relation Attention for Temporal Action Localization",
    "authors": [
      "Peihao Chen",
      "Chuang Gan",
      "Guangyao Shen",
      "Wenbing Huang",
      "Runhao Zeng",
      "Mingkui Tan"
    ],
    "year": "2020",
    "journal": "IEEE Transactions on Multimedia",
    "volume": "22",
    "number": "10",
    "pages": "2723-2733",
    "keywords": "Proposals;Feature extraction;Task analysis;Object detection;Deep learning;Sports;Semantics;Temporal action localization;relation attention",
    "doi": "10.1109/TMM.2019.2959977",
    "url": "https://ieeexplore.ieee.org/document/8933113",
    "arxiv": "https://arxiv.org/abs/2011.07949",
    "category": "Vision Learning & Navigation"
  },
  {
    "id": "huang2020locationawaregraphconvolutionalnetworks",
    "type": "misc",
    "title": "Location-aware Graph Convolutional Networks for Video Question Answering",
    "authors": [
      "Deng Huang",
      "Peihao Chen",
      "Runhao Zeng",
      "Qing Du",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2020",
    "eprint": "2008.09105",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2008.09105",
    "arxiv": "https://arxiv.org/abs/2008.09105",
    "category": "Vision Learning & Navigation"
  },
  {
    "id": "Chen_2020",
    "type": "article",
    "title": "Generating Visually Aligned Sound From Videos",
    "volume": "29",
    "issn": "1941-0042",
    "url": "http://dx.doi.org/10.1109/TIP.2020.3009820",
    "arxiv": "https://arxiv.org/abs/2008.09105",
    "doi": "10.1109/tip.2020.3009820",
    "journal": "IEEE Transactions on Image Processing",
    "publisher": "Institute of Electrical and Electronics Engineers (IEEE)",
    "authors": [
      "Peihao Chen",
      "Yang Zhang",
      "Mingkui Tan",
      "Hongdong Xiao",
      "Deng Huang",
      "Chuang Gan"
    ],
    "year": "2020",
    "pages": "8292-8302",
    "category": "Audio-Visual Learning"
  },
  {
    "id": "gan2020foleymusiclearninggenerate",
    "type": "misc",
    "title": "Foley Music: Learning to Generate Music from Videos",
    "authors": [
      "Chuang Gan",
      "Deng Huang",
      "Peihao Chen",
      "Joshua B. Tenenbaum",
      "Antonio Torralba"
    ],
    "year": "2020",
    "eprint": "2007.10984",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2007.10984",
    "arxiv": "https://arxiv.org/abs/2007.10984",
    "category": "Audio-Visual Learning"
  },
  {
    "id": "zeng2020denseregressionnetworkvideo",
    "type": "misc",
    "title": "Dense Regression Network for Video Grounding",
    "authors": [
      "Runhao Zeng",
      "Haoming Xu",
      "Wenbing Huang",
      "Peihao Chen",
      "Mingkui Tan",
      "Chuang Gan"
    ],
    "year": "2020",
    "eprint": "2004.03545",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/2004.03545",
    "arxiv": "https://arxiv.org/abs/2004.03545",
    "category": "Vision Learning & Navigation"
  },
  {
    "id": "8737877",
    "type": "article",
    "title": "Breaking Winner-Takes-All: Iterative-Winners-Out Networks for Weakly Supervised Temporal Action Localization",
    "authors": [
      "Runhao Zeng",
      "Chuang Gan",
      "Peihao Chen",
      "Wenbing Huang",
      "Qingyao Wu",
      "Mingkui Tan"
    ],
    "year": "2019",
    "journal": "IEEE Transactions on Image Processing",
    "volume": "28",
    "number": "12",
    "pages": "5797-5808",
    "keywords": "Videos;Training;Proposals;Image segmentation;Correlation;Object detection;Semantics;Weakly supervised learning;action localization;winners-out;untrimmed video",
    "doi": "10.1109/TIP.2019.2922108",
    "url": "https://ieeexplore.ieee.org/document/8737877",
    "arxiv": "https://arxiv.org/abs/2004.03545",
    "category": "Vision Learning & Navigation"
  },
  {
    "id": "gan2019selfsupervisedmovingvehicletracking",
    "type": "misc",
    "title": "Self-supervised Moving Vehicle Tracking with Stereo Sound",
    "authors": [
      "Chuang Gan",
      "Hang Zhao",
      "Peihao Chen",
      "David Cox",
      "Antonio Torralba"
    ],
    "year": "2019",
    "eprint": "1910.11760",
    "archiveprefix": "arXiv",
    "primaryclass": "cs.CV",
    "url": "https://arxiv.org/abs/1910.11760",
    "arxiv": "https://arxiv.org/abs/1910.11760",
    "category": "Audio-Visual Learning"
  },
  {
    "id": "Zhao_2018_ECCV",
    "type": "inproceedings",
    "title": "The Sound of Pixels",
    "authors": [
      "Hang Zhao",
      "Chuang Gan",
      "Andrew Rouditchenko",
      "Carl Vondrick",
      "Josh McDermott",
      "Antonio Torralba"
    ],
    "booktitle": "The European Conference on Computer Vision (ECCV)",
    "month": "September",
    "year": "2018",
    "selected": true,
    "preview": "./soundofpixels.png",
    "website": "http://sound-of-pixels.csail.mit.edu/",
    "arxiv": "https://arxiv.org/abs/1804.03160",
    "pdf": "https://arxiv.org/pdf/1804.03160",
    "code": "https://github.com/hangzhaomit/Sound-of-Pixels",
    "category": "Audio-Visual Learning"
  }
]
